P8015\_hw2\_db3180
================
Divya Bisht
10/2/2018

Problem 1
---------

Importing NYC Transit data

``` r
NYC_transport = read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
janitor::clean_names() %>% 
select(line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending,       
       entrance_type, ada) %>%

mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_integer(),
    ##   Route9 = col_integer(),
    ##   Route10 = col_integer(),
    ##   Route11 = col_integer(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
NYC_transport
```

    ## # A tibble: 1,868 x 19
    ##    line  station_name station_latitude station_longitu… route1 route2
    ##    <chr> <chr>                   <dbl>            <dbl> <chr>  <chr> 
    ##  1 4 Av… 25th St                  40.7            -74.0 R      <NA>  
    ##  2 4 Av… 25th St                  40.7            -74.0 R      <NA>  
    ##  3 4 Av… 36th St                  40.7            -74.0 N      R     
    ##  4 4 Av… 36th St                  40.7            -74.0 N      R     
    ##  5 4 Av… 36th St                  40.7            -74.0 N      R     
    ##  6 4 Av… 45th St                  40.6            -74.0 R      <NA>  
    ##  7 4 Av… 45th St                  40.6            -74.0 R      <NA>  
    ##  8 4 Av… 45th St                  40.6            -74.0 R      <NA>  
    ##  9 4 Av… 45th St                  40.6            -74.0 R      <NA>  
    ## 10 4 Av… 53rd St                  40.6            -74.0 R      <NA>  
    ## # ... with 1,858 more rows, and 13 more variables: route3 <chr>,
    ## #   route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>, route8 <int>,
    ## #   route9 <int>, route10 <int>, route11 <int>, entry <lgl>,
    ## #   vending <chr>, entrance_type <chr>, ada <lgl>

This dataset has 19 variables (line, station\_name, station\_latitude, station\_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance\_type, ada). The cleaning so far has included using the janitor function. There are 1868 rows and 19 columns. The data are tidy, but the route8 and route9 data are numeric variables while all the other route data are factor variables.

Answer the following questions using these data:

How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St A/B/C/D; 125st 1; 125st 4/5); the distinct function may be useful here.

The number of distint stations are: 465

The number of stations that are ADA compliant are: 1

``` r
prop_vend = 
(nrow(
  NYC_transport %>% 
  filter(entry == TRUE) %>%
  filter(vending == "NO")
)
  /
nrow(NYC_transport %>% 
  filter(vending == "NO")
))
```

The proportion of station entrances/exits without vending allow entrances is: 0.3770492

Reformatting data

``` r
NYC_tidy_transport = gather(NYC_transport, key = route_number, value = route_name, route1:route11)
```

Stations of the A train:

``` r
nrow(
  NYC_tidy_transport %>%
   distinct(line, station_name, route_name) %>% 
   filter(route_name == "A")
   )
```

    ## [1] 60

Number of A train stations are ADA compliant

``` r
nrow(
  NYC_tidy_transport %>%
   distinct(line, station_name, route_name, ada) %>% 
   filter(route_name == "A") %>%
   filter(ada == TRUE))
```

    ## [1] 17

Problem 2
---------

Import Mr. TrashWheel

``` r
library(readxl)
trash_data = read_excel("./HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet =  "Mr. Trash Wheel", 
  range = "A2:N258") %>%
  janitor::clean_names() %>%
  filter(!is.na(dumpster)) %>%
  mutate(sports_balls = round(sports_balls)) %>%
  mutate(sports_balls = as.integer(sports_balls))
```

Precipitation data

``` r
precip_data16 = read_excel("./HealthyHarborWaterWheelTotals2018-7-28.xlsx", 
    sheet = "2016 Precipitation", 
    range = "A2:B14") %>%
    janitor::clean_names() %>% 
    mutate(year = 2016)

precip_data17 = read_excel("./HealthyHarborWaterWheelTotals2018-7-28.xlsx", 
    sheet = "2017 Precipitation", 
    range = "A2:B14") %>%
    janitor::clean_names() %>% 
    filter(!is.na(total)) %>%
    mutate(year = 2017)

preci_combined = full_join(precip_data16, precip_data17) %>%
mutate(month = month.name[month])
```

    ## Joining, by = c("month", "total", "year")

The precipitation data above describe the monthly precipitation amounts in both 2016/2017. Both datasets have 12 rows and 3 columns. In 2017, the total precipitation was 32.93.

``` r
median_sports = trash_data %>%
filter(year == 2016) %>%
  pull(sports_balls) %>% 
median(na.rm = TRUE)
```

The median number of sports balls in a dumpster in 2016: 26

Problem 3
---------

``` r
devtools::install_github("p8105/p8105.datasets")
```

    ## Skipping install of 'p8105.datasets' from a github remote, the SHA1 (21f5ad1c) has not changed since last install.
    ##   Use `force = TRUE` to force installation

``` r
library(p8105.datasets)

brfss_data = brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic == "Overall Health") %>% 
  select(-class, -topic, -question, -sample_size, -(confidence_limit_low:geo_location)) %>%
  rename(state = locationabbr, county = locationdesc) %>%
  spread(key = response, value = data_value) %>%
  janitor::clean_names() %>%
  mutate(proportion_responses = (excellent + very_good)/100)
```

``` r
unique_location = 
(nrow(
  brfss_data %>%
   distinct(state, county)))
```

There are 404 in the dataset

``` r
unique_state = 
(nrow(
  brfss_data %>%
   distinct(state)))
```

There are 51. This is because the list includes Washington, DC.

``` r
state_most = 
  brfss_data %>%
  count(state) %>%
  arrange(desc(n))
```

New Jersey has been mentioned the most: 146 times.

``` r
excellent_2002 = brfss_data %>%
filter(year == 2002) %>%
  pull(excellent) %>% 
median(na.rm = TRUE)
```

The median value of the "Excellent" response value is 23.6.
